{
    "cells": [
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# 1. Exploring Data Sources and Use Cases"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "## Initial Data Exploration"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "### The use-case to implement is collected from https://www.kaggle.com/datasets - flower-recognition dataset"
        },
        {
            "cell_type": "code",
            "execution_count": 2,
            "metadata": {},
            "outputs": [],
            "source": "# The code was removed by Watson Studio for sharing."
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Extract Transform Load (ETL)"
        },
        {
            "cell_type": "code",
            "execution_count": 3,
            "metadata": {},
            "outputs": [],
            "source": "from io import BytesIO\nimport os\nimport zipfile\n\nzip_ref = zipfile.ZipFile(BytesIO(streaming_body_2.read()), 'r')\n\nzip_ref .extractall(\"../input/flower5/\")\n#zip_ref.close()"
        },
        {
            "cell_type": "code",
            "execution_count": 4,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "['sunflower', 'dandelion', 'rose', 'daisy', 'tulip']\n"
                }
            ],
            "source": "data = \"../input/flower5/flowers\"\n\n# List out the directories inside the main input folder\n\nfolders = os.listdir(data)\n\nprint(folders)"
        },
        {
            "cell_type": "code",
            "execution_count": 5,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting package metadata (current_repodata.json): done\nSolving environment: done\n\n## Package Plan ##\n\n  environment location: /home/spark/shared/conda/envs/python3.6\n\n  added / updated specs:\n    - scikit-image\n\n\nThe following packages will be downloaded:\n\n    package                    |            build\n    ---------------------------|-----------------\n    ca-certificates-2019.11.28 |       hecc5488_0         145 KB  conda-forge\n    certifi-2019.11.28         |           py36_0         149 KB  conda-forge\n    cloudpickle-1.2.2          |             py_1          23 KB  conda-forge\n    cycler-0.10.0              |             py_2           9 KB  conda-forge\n    cytoolz-0.10.1             |   py36h516909a_0         431 KB  conda-forge\n    dask-core-2.9.0            |             py_0         581 KB  conda-forge\n    dbus-1.13.6                |       he372182_0         602 KB  conda-forge\n    decorator-4.4.1            |             py_0          11 KB  conda-forge\n    expat-2.2.5                |    he1b5a44_1004         191 KB  conda-forge\n    fontconfig-2.13.1          |    he4413a7_1000         327 KB  conda-forge\n    freetype-2.10.0            |       he983fc9_1         884 KB  conda-forge\n    gettext-0.19.8.1           |    hc5be6a0_1002         3.6 MB  conda-forge\n    glib-2.58.3                |py36h6f030ca_1002         3.3 MB  conda-forge\n    gst-plugins-base-1.14.5    |       h0935bb2_0         6.8 MB  conda-forge\n    gstreamer-1.14.5           |       h36ae1b5_0         4.5 MB  conda-forge\n    icu-58.2                   |    hf484d3e_1000        22.6 MB  conda-forge\n    imageio-2.6.1              |           py36_0         3.3 MB  conda-forge\n    jpeg-9c                    |    h14c3975_1001         251 KB  conda-forge\n    kiwisolver-1.1.0           |   py36hc9558a2_0          86 KB  conda-forge\n    libblas-3.8.0              |      14_openblas          10 KB  conda-forge\n    libcblas-3.8.0             |      14_openblas          10 KB  conda-forge\n    libgfortran-ng-7.3.0       |       hdf63c60_2         1.7 MB  conda-forge\n    libiconv-1.15              |    h516909a_1005         2.0 MB  conda-forge\n    liblapack-3.8.0            |      14_openblas          10 KB  conda-forge\n    libopenblas-0.3.7          |       h5ec1e0e_5         7.6 MB  conda-forge\n    libpng-1.6.37              |       hed695b0_0         343 KB  conda-forge\n    libtiff-4.1.0              |       hc3755c2_1         609 KB  conda-forge\n    libuuid-2.32.1             |    h14c3975_1000          26 KB  conda-forge\n    libxcb-1.13                |    h14c3975_1002         396 KB  conda-forge\n    libxml2-2.9.9              |       hea5a465_1         1.6 MB\n    lz4-c-1.8.3                |    he1b5a44_1001         187 KB  conda-forge\n    matplotlib-3.1.1           |   py36h5429711_0         5.0 MB\n    networkx-2.4               |             py_0         1.2 MB  conda-forge\n    numpy-1.17.3               |   py36h95a1406_0         5.2 MB  conda-forge\n    olefile-0.46               |             py_0          31 KB  conda-forge\n    openssl-1.1.1d             |       h516909a_0         2.1 MB  conda-forge\n    pcre-8.43                  |       he1b5a44_0         257 KB  conda-forge\n    pillow-6.2.1               |   py36h34e0f95_0         640 KB\n    pthread-stubs-0.4          |    h14c3975_1001           5 KB  conda-forge\n    pyparsing-2.4.5            |             py_0          58 KB  conda-forge\n    pyqt-5.9.2                 |   py36hcca6a23_4         5.7 MB  conda-forge\n    python-dateutil-2.8.1      |             py_0         220 KB  conda-forge\n    pytz-2019.3                |             py_0         237 KB  conda-forge\n    pywavelets-1.1.1           |   py36hc1659b7_0         4.4 MB  conda-forge\n    qt-5.9.7                   |       h52cfd70_2        85.9 MB  conda-forge\n    scikit-image-0.15.0        |   py36he6710b0_0        24.8 MB\n    scipy-1.3.2                |   py36h921218d_0        18.0 MB  conda-forge\n    sip-4.19.8                 |   py36hf484d3e_0         274 KB\n    six-1.13.0                 |           py36_0          22 KB  conda-forge\n    toolz-0.10.0               |             py_0          46 KB  conda-forge\n    tornado-6.0.3              |   py36h516909a_0         636 KB  conda-forge\n    xorg-libxau-1.0.9          |       h14c3975_0          13 KB  conda-forge\n    xorg-libxdmcp-1.1.3        |       h516909a_0          18 KB  conda-forge\n    zstd-1.4.4                 |       h3b9ef0a_1         989 KB  conda-forge\n    ------------------------------------------------------------\n                                           Total:       217.7 MB\n\nThe following NEW packages will be INSTALLED:\n\n  cloudpickle        conda-forge/noarch::cloudpickle-1.2.2-py_1\n  cycler             conda-forge/noarch::cycler-0.10.0-py_2\n  cytoolz            conda-forge/linux-64::cytoolz-0.10.1-py36h516909a_0\n  dask-core          conda-forge/noarch::dask-core-2.9.0-py_0\n  dbus               conda-forge/linux-64::dbus-1.13.6-he372182_0\n  decorator          conda-forge/noarch::decorator-4.4.1-py_0\n  expat              conda-forge/linux-64::expat-2.2.5-he1b5a44_1004\n  fontconfig         conda-forge/linux-64::fontconfig-2.13.1-he4413a7_1000\n  freetype           conda-forge/linux-64::freetype-2.10.0-he983fc9_1\n  gettext            conda-forge/linux-64::gettext-0.19.8.1-hc5be6a0_1002\n  glib               conda-forge/linux-64::glib-2.58.3-py36h6f030ca_1002\n  gst-plugins-base   conda-forge/linux-64::gst-plugins-base-1.14.5-h0935bb2_0\n  gstreamer          conda-forge/linux-64::gstreamer-1.14.5-h36ae1b5_0\n  icu                conda-forge/linux-64::icu-58.2-hf484d3e_1000\n  imageio            conda-forge/linux-64::imageio-2.6.1-py36_0\n  jpeg               conda-forge/linux-64::jpeg-9c-h14c3975_1001\n  kiwisolver         conda-forge/linux-64::kiwisolver-1.1.0-py36hc9558a2_0\n  libblas            conda-forge/linux-64::libblas-3.8.0-14_openblas\n  libcblas           conda-forge/linux-64::libcblas-3.8.0-14_openblas\n  libgfortran-ng     conda-forge/linux-64::libgfortran-ng-7.3.0-hdf63c60_2\n  libiconv           conda-forge/linux-64::libiconv-1.15-h516909a_1005\n  liblapack          conda-forge/linux-64::liblapack-3.8.0-14_openblas\n  libopenblas        conda-forge/linux-64::libopenblas-0.3.7-h5ec1e0e_5\n  libpng             conda-forge/linux-64::libpng-1.6.37-hed695b0_0\n  libtiff            conda-forge/linux-64::libtiff-4.1.0-hc3755c2_1\n  libuuid            conda-forge/linux-64::libuuid-2.32.1-h14c3975_1000\n  libxcb             conda-forge/linux-64::libxcb-1.13-h14c3975_1002\n  libxml2            pkgs/main/linux-64::libxml2-2.9.9-hea5a465_1\n  lz4-c              conda-forge/linux-64::lz4-c-1.8.3-he1b5a44_1001\n  matplotlib         pkgs/main/linux-64::matplotlib-3.1.1-py36h5429711_0\n  networkx           conda-forge/noarch::networkx-2.4-py_0\n  numpy              conda-forge/linux-64::numpy-1.17.3-py36h95a1406_0\n  olefile            conda-forge/noarch::olefile-0.46-py_0\n  pcre               conda-forge/linux-64::pcre-8.43-he1b5a44_0\n  pillow             pkgs/main/linux-64::pillow-6.2.1-py36h34e0f95_0\n  pthread-stubs      conda-forge/linux-64::pthread-stubs-0.4-h14c3975_1001\n  pyparsing          conda-forge/noarch::pyparsing-2.4.5-py_0\n  pyqt               conda-forge/linux-64::pyqt-5.9.2-py36hcca6a23_4\n  python-dateutil    conda-forge/noarch::python-dateutil-2.8.1-py_0\n  pytz               conda-forge/noarch::pytz-2019.3-py_0\n  pywavelets         conda-forge/linux-64::pywavelets-1.1.1-py36hc1659b7_0\n  qt                 conda-forge/linux-64::qt-5.9.7-h52cfd70_2\n  scikit-image       pkgs/main/linux-64::scikit-image-0.15.0-py36he6710b0_0\n  scipy              conda-forge/linux-64::scipy-1.3.2-py36h921218d_0\n  sip                pkgs/main/linux-64::sip-4.19.8-py36hf484d3e_0\n  six                conda-forge/linux-64::six-1.13.0-py36_0\n  toolz              conda-forge/noarch::toolz-0.10.0-py_0\n  tornado            conda-forge/linux-64::tornado-6.0.3-py36h516909a_0\n  xorg-libxau        conda-forge/linux-64::xorg-libxau-1.0.9-h14c3975_0\n  xorg-libxdmcp      conda-forge/linux-64::xorg-libxdmcp-1.1.3-h516909a_0\n  zstd               conda-forge/linux-64::zstd-1.4.4-h3b9ef0a_1\n\nThe following packages will be UPDATED:\n\n  ca-certificates    pkgs/main::ca-certificates-2019.5.15-1 --> conda-forge::ca-certificates-2019.11.28-hecc5488_0\n  certifi               pkgs/main::certifi-2019.6.16-py36_1 --> conda-forge::certifi-2019.11.28-py36_0\n\nThe following packages will be SUPERSEDED by a higher-priority channel:\n\n  openssl              pkgs/main::openssl-1.1.1d-h7b6447c_0 --> conda-forge::openssl-1.1.1d-h516909a_0\n\n\n\nDownloading and Extracting Packages\nxorg-libxdmcp-1.1.3  | 18 KB     | ##################################### | 100% \ngstreamer-1.14.5     | 4.5 MB    | ##################################### | 100% \nscipy-1.3.2          | 18.0 MB   | ##################################### | 100% \nglib-2.58.3          | 3.3 MB    | ##################################### | 100% \nscikit-image-0.15.0  | 24.8 MB   | ##################################### | 100% \nlibopenblas-0.3.7    | 7.6 MB    | ##################################### | 100% \nlibcblas-3.8.0       | 10 KB     | ##################################### | 100% \nolefile-0.46         | 31 KB     | ##################################### | 100% \nnetworkx-2.4         | 1.2 MB    | ##################################### | 100% \ndbus-1.13.6          | 602 KB    | ##################################### | 100% \nca-certificates-2019 | 145 KB    | ##################################### | 100% \ndecorator-4.4.1      | 11 KB     | ##################################### | 100% \ncycler-0.10.0        | 9 KB      | ##################################### | 100% \npcre-8.43            | 257 KB    | ##################################### | 100% \ncertifi-2019.11.28   | 149 KB    | ##################################### | 100% \nkiwisolver-1.1.0     | 86 KB     | ##################################### | 100% \nsip-4.19.8           | 274 KB    | ##################################### | 100% \npillow-6.2.1         | 640 KB    | ##################################### | 100% \ncloudpickle-1.2.2    | 23 KB     | ##################################### | 100% \ntoolz-0.10.0         | 46 KB     | ##################################### | 100% \nlibgfortran-ng-7.3.0 | 1.7 MB    | ##################################### | 100% \nlibiconv-1.15        | 2.0 MB    | ##################################### | 100% \npyparsing-2.4.5      | 58 KB     | ##################################### | 100% \npytz-2019.3          | 237 KB    | ##################################### | 100% \nqt-5.9.7             | 85.9 MB   | ##################################### | 100% \nicu-58.2             | 22.6 MB   | ##################################### | 100% \ngst-plugins-base-1.1 | 6.8 MB    | ##################################### | 100% \nlibblas-3.8.0        | 10 KB     | ##################################### | 100% \ncytoolz-0.10.1       | 431 KB    | ##################################### | 100% \njpeg-9c              | 251 KB    | ##################################### | 100% \npywavelets-1.1.1     | 4.4 MB    | ##################################### | 100% \nmatplotlib-3.1.1     | 5.0 MB    | ##################################### | 100% \nlibxcb-1.13          | 396 KB    | ##################################### | 100% \nlz4-c-1.8.3          | 187 KB    | ##################################### | 100% \nlibuuid-2.32.1       | 26 KB     | ##################################### | 100% \npthread-stubs-0.4    | 5 KB      | ##################################### | 100% \nexpat-2.2.5          | 191 KB    | ##################################### | 100% \nliblapack-3.8.0      | 10 KB     | ##################################### | 100% \ngettext-0.19.8.1     | 3.6 MB    | ##################################### | 100% \nlibxml2-2.9.9        | 1.6 MB    | ##################################### | 100% \nxorg-libxau-1.0.9    | 13 KB     | ##################################### | 100% \nimageio-2.6.1        | 3.3 MB    | ##################################### | 100% \nlibtiff-4.1.0        | 609 KB    | ##################################### | 100% \nfreetype-2.10.0      | 884 KB    | ##################################### | 100% \nzstd-1.4.4           | 989 KB    | ##################################### | 100% \ndask-core-2.9.0      | 581 KB    | ##################################### | 100% \nopenssl-1.1.1d       | 2.1 MB    | ##################################### | 100% \nnumpy-1.17.3         | 5.2 MB    | ##################################### | 100% \nsix-1.13.0           | 22 KB     | ##################################### | 100% \ntornado-6.0.3        | 636 KB    | ##################################### | 100% \npython-dateutil-2.8. | 220 KB    | ##################################### | 100% \nlibpng-1.6.37        | 343 KB    | ##################################### | 100% \npyqt-5.9.2           | 5.7 MB    | ##################################### | 100% \nfontconfig-2.13.1    | 327 KB    | ##################################### | 100% \nPreparing transaction: done\nVerifying transaction: done\nExecuting transaction: done\n"
                }
            ],
            "source": "!conda install -c conda-forge scikit-image"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Feature Creation"
        },
        {
            "cell_type": "code",
            "execution_count": 6,
            "metadata": {},
            "outputs": [],
            "source": "import matplotlib.pyplot as plt\nimport numpy as np\nfrom os import listdir\nfrom os.path import join\nfrom skimage.io import imread\nfrom skimage import transform as tf\nimport pandas\nimport os\nimport random\nimage_names1 = []\ntrain_labels1 = []\ntrain_images1 = []\n\nsize = 28,28\n\nfor folder in folders:\n    for file in os.listdir(os.path.join(data,folder)):\n        if file.endswith(\"jpg\"):\n            image_names1.append(os.path.join(data,folder,file))\n            train_labels1.append(folder)\n            img = imread(os.path.join(data,folder,file))\n            im = tf.resize(img,size)\n            train_images1.append(im)\n        else:\n            continue"
        },
        {
            "cell_type": "code",
            "execution_count": 9,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "LabelEncoder()"
                    },
                    "execution_count": 9,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from sklearn import preprocessing\nle = preprocessing.LabelEncoder()\nle.fit([\"tulip\", \"dandelion\", \"sunflower\", \"daisy\", \"rose\"])\n"
        },
        {
            "cell_type": "code",
            "execution_count": 10,
            "metadata": {},
            "outputs": [],
            "source": "train = np.array(train_images1)\n\n\n\ntrain = train.astype('float32') / 255.0\n\n\nlabels =  le.transform(train_labels1)\n\n\n# Convert the  list to numpy array type\n\ntrain_image = np.array(train)\nlabels_image = np.array(labels)\n"
        },
        {
            "cell_type": "code",
            "execution_count": 42,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([1, 4, 3, 4, 1, 0, 2, 0, 4])"
                    },
                    "execution_count": 42,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "\nfrom sklearn.model_selection import train_test_split\n\ntrain_images, test_images,train_labels, test_labels = train_test_split(train_image,labels_image, test_size=0.2,shuffle=True)\n"
        },
        {
            "cell_type": "code",
            "execution_count": 12,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Collecting tensorflow==1.14.0\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/de/f0/96fb2e0412ae9692dbf400e5b04432885f677ad6241c088ccc5fe7724d69/tensorflow-1.14.0-cp36-cp36m-manylinux1_x86_64.whl (109.2MB)\n\u001b[K    100% |################################| 109.2MB 150kB/s eta 0:00:01K    34% |###########                     | 38.2MB 69.1MB/s eta 0:00:02[K    45% |##############                  | 49.3MB 36.0MB/s eta 0:00:02    54% |#################               | 60.0MB 10.4MB/s eta 0:00:05    57% |##################              | 62.3MB 64.2MB/s eta 0:00:01\n\u001b[?25hCollecting astor>=0.6.0 (from tensorflow==1.14.0)\n  Downloading https://files.pythonhosted.org/packages/c3/88/97eef84f48fa04fbd6750e62dcceafba6c63c81b7ac1420856c8dcc0a3f9/astor-0.8.1-py2.py3-none-any.whl\nCollecting six>=1.10.0 (from tensorflow==1.14.0)\n  Downloading https://files.pythonhosted.org/packages/65/26/32b8464df2a97e6dd1b656ed26b2c194606c16fe163c695a992b36c11cdf/six-1.13.0-py2.py3-none-any.whl\nCollecting absl-py>=0.7.0 (from tensorflow==1.14.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3b/72/e6e483e2db953c11efa44ee21c5fdb6505c4dffa447b4263ca8af6676b62/absl-py-0.8.1.tar.gz (103kB)\n\u001b[K    100% |################################| 112kB 2.8MB/s eta 0:00:01\n\u001b[?25hCollecting keras-preprocessing>=1.0.5 (from tensorflow==1.14.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/28/6a/8c1f62c37212d9fc441a7e26736df51ce6f0e38455816445471f10da4f0a/Keras_Preprocessing-1.1.0-py2.py3-none-any.whl (41kB)\n\u001b[K    100% |################################| 51kB 1.9MB/s eta 0:00:01\n\u001b[?25hCollecting tensorboard<1.15.0,>=1.14.0 (from tensorflow==1.14.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/2d/2ed263449a078cd9c8a9ba50ebd50123adf1f8cfbea1492f9084169b89d9/tensorboard-1.14.0-py3-none-any.whl (3.1MB)\n\u001b[K    100% |################################| 3.2MB 2.2MB/s eta 0:00:01\n\u001b[?25hCollecting termcolor>=1.1.0 (from tensorflow==1.14.0)\n  Downloading https://files.pythonhosted.org/packages/8a/48/a76be51647d0eb9f10e2a4511bf3ffb8cc1e6b14e9e4fab46173aa79f981/termcolor-1.1.0.tar.gz\nCollecting gast>=0.2.0 (from tensorflow==1.14.0)\n  Downloading https://files.pythonhosted.org/packages/1f/04/4e36c33f8eb5c5b6c622a1f4859352a6acca7ab387257d4b3c191d23ec1d/gast-0.3.2.tar.gz\nCollecting tensorflow-estimator<1.15.0rc0,>=1.14.0rc0 (from tensorflow==1.14.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/3c/d5/21860a5b11caf0678fbc8319341b0ae21a07156911132e0e71bffed0510d/tensorflow_estimator-1.14.0-py2.py3-none-any.whl (488kB)\n\u001b[K    100% |################################| 491kB 2.9MB/s eta 0:00:01\n\u001b[?25hCollecting grpcio>=1.8.6 (from tensorflow==1.14.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/27/28/280658104af767431cf25e397157c4f4a8724a446f9dd5a34dac9812e9c9/grpcio-1.25.0-cp36-cp36m-manylinux2010_x86_64.whl (2.4MB)\n\u001b[K    100% |################################| 2.4MB 1.8MB/s eta 0:00:01\n\u001b[?25hCollecting keras-applications>=1.0.6 (from tensorflow==1.14.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/71/e3/19762fdfc62877ae9102edf6342d71b28fbfd9dea3d2f96a882ce099b03f/Keras_Applications-1.0.8-py3-none-any.whl (50kB)\n\u001b[K    100% |################################| 51kB 1.8MB/s eta 0:00:01\n\u001b[?25hCollecting protobuf>=3.6.1 (from tensorflow==1.14.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/b8/be/438a8b90701aacfd7d741541571a236edbcf46f772caa25fcb27c4937e9e/protobuf-3.11.1-cp36-cp36m-manylinux1_x86_64.whl (1.3MB)\n\u001b[K    100% |################################| 1.3MB 2.6MB/s eta 0:00:01\n\u001b[?25hCollecting google-pasta>=0.1.6 (from tensorflow==1.14.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c3/fd/1e86bc4837cc9a3a5faf3db9b1854aa04ad35b5f381f9648fbe81a6f94e4/google_pasta-0.1.8-py3-none-any.whl (57kB)\n\u001b[K    100% |################################| 61kB 1.8MB/s eta 0:00:01\n\u001b[?25hCollecting wrapt>=1.11.1 (from tensorflow==1.14.0)\n  Downloading https://files.pythonhosted.org/packages/23/84/323c2415280bc4fc880ac5050dddfb3c8062c2552b34c2e512eb4aa68f79/wrapt-1.11.2.tar.gz\nCollecting numpy<2.0,>=1.14.5 (from tensorflow==1.14.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d2/ab/43e678759326f728de861edbef34b8e2ad1b1490505f20e0d1f0716c3bf4/numpy-1.17.4-cp36-cp36m-manylinux1_x86_64.whl (20.0MB)\n\u001b[K    100% |################################| 20.0MB 684kB/s eta 0:00:01\n\u001b[?25hCollecting wheel>=0.26 (from tensorflow==1.14.0)\n  Downloading https://files.pythonhosted.org/packages/00/83/b4a77d044e78ad1a45610eb88f745be2fd2c6d658f9798a15e384b7d57c9/wheel-0.33.6-py2.py3-none-any.whl\nCollecting markdown>=2.6.8 (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/c0/4e/fd492e91abdc2d2fcb70ef453064d980688762079397f779758e055f6575/Markdown-3.1.1-py2.py3-none-any.whl (87kB)\n\u001b[K    100% |################################| 92kB 1.9MB/s eta 0:00:01\n\u001b[?25hCollecting setuptools>=41.0.0 (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/54/28/c45d8b54c1339f9644b87663945e54a8503cfef59cf0f65b3ff5dd17cf64/setuptools-42.0.2-py2.py3-none-any.whl (583kB)\n\u001b[K    100% |################################| 583kB 2.6MB/s eta 0:00:01\n\u001b[?25hCollecting werkzeug>=0.11.15 (from tensorboard<1.15.0,>=1.14.0->tensorflow==1.14.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/ce/42/3aeda98f96e85fd26180534d36570e4d18108d62ae36f87694b476b83d6f/Werkzeug-0.16.0-py2.py3-none-any.whl (327kB)\n\u001b[K    100% |################################| 327kB 3.3MB/s eta 0:00:01\n\u001b[?25hCollecting h5py (from keras-applications>=1.0.6->tensorflow==1.14.0)\n\u001b[?25l  Downloading https://files.pythonhosted.org/packages/60/06/cafdd44889200e5438b897388f3075b52a8ef01f28a17366d91de0fa2d05/h5py-2.10.0-cp36-cp36m-manylinux1_x86_64.whl (2.9MB)\n\u001b[K    100% |################################| 2.9MB 1.5MB/s eta 0:00:01\n\u001b[?25hBuilding wheels for collected packages: absl-py, termcolor, gast, wrapt\n  Building wheel for absl-py (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/spark/shared/.cache/pip/wheels/a7/15/a0/0a0561549ad11cdc1bc8fa1191a353efd30facf6bfb507aefc\n  Building wheel for termcolor (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/spark/shared/.cache/pip/wheels/7c/06/54/bc84598ba1daf8f970247f550b175aaaee85f68b4b0c5ab2c6\n  Building wheel for gast (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/spark/shared/.cache/pip/wheels/59/38/c6/234dc39b4f6951a0768fbc02d5b7207137a5b1d9094f0d54bf\n  Building wheel for wrapt (setup.py) ... \u001b[?25ldone\n\u001b[?25h  Stored in directory: /home/spark/shared/.cache/pip/wheels/d7/de/2e/efa132238792efb6459a96e85916ef8597fcb3d2ae51590dfd\nSuccessfully built absl-py termcolor gast wrapt\nInstalling collected packages: astor, six, absl-py, numpy, keras-preprocessing, setuptools, protobuf, wheel, markdown, werkzeug, grpcio, tensorboard, termcolor, gast, tensorflow-estimator, h5py, keras-applications, google-pasta, wrapt, tensorflow\nSuccessfully installed absl-py-0.8.1 astor-0.8.1 gast-0.3.2 google-pasta-0.1.8 grpcio-1.25.0 h5py-2.10.0 keras-applications-1.0.8 keras-preprocessing-1.1.0 markdown-3.1.1 numpy-1.17.4 protobuf-3.11.1 setuptools-42.0.2 six-1.13.0 tensorboard-1.14.0 tensorflow-1.14.0 tensorflow-estimator-1.14.0 termcolor-1.1.0 werkzeug-0.16.0 wheel-0.33.6 wrapt-1.11.2\n"
                }
            ],
            "source": "!pip install tensorflow==1.14.0"
        },
        {
            "cell_type": "code",
            "execution_count": 13,
            "metadata": {},
            "outputs": [],
            "source": "\nimport tensorflow as tf\n"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        },
        {
            "cell_type": "code",
            "execution_count": 14,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "(28, 28, 3)"
                    },
                    "execution_count": 14,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "test_images[0].shape"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Model Definition and Training"
        },
        {
            "cell_type": "code",
            "execution_count": 83,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "865/865 [==============================] - 0s 63us/sample - loss: 1.1794 - acc: 0.4925\n"
                },
                {
                    "data": {
                        "text/plain": "[1.1794200982661605, 0.49248555]"
                    },
                    "execution_count": 83,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "from tensorflow.keras import Sequential\nfrom tensorflow.keras.layers import Flatten, Dense\nfrom tensorflow.nn import relu\nfrom tensorflow.nn import softmax\nfrom tensorflow.nn import sigmoid\n\n    \nmodel = Sequential([\n    Flatten(input_shape=(28, 28,3)),\n    Dense(512, activation=relu),\n    Dense(5, activation=softmax)\n])\n\nmodel.compile(optimizer='adam', \n          loss='sparse_categorical_crossentropy',\n          metrics=['accuracy'])\n\nmodel.fit(train_images, train_labels, validation_data=(test_images, test_labels), epochs=50, verbose=0)\n\nmodel.evaluate(test_images, test_labels)"
        },
        {
            "cell_type": "markdown",
            "metadata": {},
            "source": "# Model Evaluation, Tuning, Deployment and Documentation"
        },
        {
            "cell_type": "code",
            "execution_count": 60,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "--2019-12-16 20:46:19--  https://images.all-free-download.com/images/graphiclarge/sunflower_05_hd_picture_167005.jpg\nResolving images.all-free-download.com (images.all-free-download.com)... 207.182.153.238\nConnecting to images.all-free-download.com (images.all-free-download.com)|207.182.153.238|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 37349 (36K) [image/jpeg]\nSaving to: 'sunflower_05_hd_picture_167005.jpg.2'\n\n100%[======================================>] 37,349      --.-K/s   in 0.03s   \n\n2019-12-16 20:46:20 (1.09 MB/s) - 'sunflower_05_hd_picture_167005.jpg.2' saved [37349/37349]\n\n"
                }
            ],
            "source": "!wget https://images.all-free-download.com/images/graphiclarge/sunflower_05_hd_picture_167005.jpg"
        },
        {
            "cell_type": "code",
            "execution_count": 61,
            "metadata": {},
            "outputs": [],
            "source": "!mv sunflower_05_hd_picture_167005.jpg sunflower.jpg"
        },
        {
            "cell_type": "code",
            "execution_count": 62,
            "metadata": {},
            "outputs": [],
            "source": "from keras.preprocessing import image\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nimport numpy as np\n\n\nimg_path = 'sunflower.jpg'\nimg = image.load_img(img_path, target_size=(28, 28))\nx = image.img_to_array(img)\nx.shape\n#img = x.astype('float32') / 255.0\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)"
        },
        {
            "cell_type": "code",
            "execution_count": 84,
            "metadata": {},
            "outputs": [],
            "source": "preds = model.predict(x)"
        },
        {
            "cell_type": "code",
            "execution_count": 85,
            "metadata": {},
            "outputs": [
                {
                    "data": {
                        "text/plain": "array([[0., 1., 0., 0., 0.]], dtype=float32)"
                    },
                    "execution_count": 85,
                    "metadata": {},
                    "output_type": "execute_result"
                }
            ],
            "source": "preds\n"
        },
        {
            "cell_type": "code",
            "execution_count": 99,
            "metadata": {},
            "outputs": [],
            "source": "position = np.argmax(preds)"
        },
        {
            "cell_type": "code",
            "execution_count": 102,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Predicted: ['dandelion']\n"
                }
            ],
            "source": "print('Predicted:', le.inverse_transform([position]))"
        },
        {
            "cell_type": "code",
            "execution_count": 118,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "--2019-12-16 22:40:48--  https://upload.wikimedia.org/wikipedia/commons/5/51/Small_Red_Rose.JPG\nResolving upload.wikimedia.org (upload.wikimedia.org)... 208.80.154.240, 2620:0:861:ed1a::2:b\nConnecting to upload.wikimedia.org (upload.wikimedia.org)|208.80.154.240|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 1380091 (1.3M) [image/jpeg]\nSaving to: 'Small_Red_Rose.JPG'\n\n100%[======================================>] 1,380,091   4.73MB/s   in 0.3s   \n\n2019-12-16 22:40:48 (4.73 MB/s) - 'Small_Red_Rose.JPG' saved [1380091/1380091]\n\n"
                }
            ],
            "source": "!wget https://upload.wikimedia.org/wikipedia/commons/5/51/Small_Red_Rose.JPG"
        },
        {
            "cell_type": "code",
            "execution_count": 123,
            "metadata": {},
            "outputs": [],
            "source": "!mv Small_Red_Rose.JPG rose.jpg"
        },
        {
            "cell_type": "code",
            "execution_count": 124,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Predicted: ['rose']\n"
                }
            ],
            "source": "from keras.preprocessing import image\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nimport numpy as np\n\n\nimg_path = 'rose.jpg'\nimg = image.load_img(img_path, target_size=(28, 28))\nx = image.img_to_array(img)\nx.shape\n#img = x.astype('float32') / 255.0\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\npreds = model.predict(x)\nposition = np.argmax(preds)\nprint('Predicted:', le.inverse_transform([position]))"
        },
        {
            "cell_type": "code",
            "execution_count": 128,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "--2019-12-16 22:44:07--  https://images.all-free-download.com/images/graphiclarge/dandelion_204752.jpg\nResolving images.all-free-download.com (images.all-free-download.com)... 207.182.153.238\nConnecting to images.all-free-download.com (images.all-free-download.com)|207.182.153.238|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 61572 (60K) [image/jpeg]\nSaving to: 'dandelion_204752.jpg'\n\n100%[======================================>] 61,572      --.-K/s   in 0.07s   \n\n2019-12-16 22:44:08 (857 KB/s) - 'dandelion_204752.jpg' saved [61572/61572]\n\n"
                }
            ],
            "source": "!wget  https://images.all-free-download.com/images/graphiclarge/dandelion_204752.jpg"
        },
        {
            "cell_type": "code",
            "execution_count": 129,
            "metadata": {},
            "outputs": [],
            "source": "!mv dandelion_204752.jpg dandelion.jpg"
        },
        {
            "cell_type": "code",
            "execution_count": 130,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Predicted: ['dandelion']\n"
                }
            ],
            "source": "from keras.preprocessing import image\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nimport numpy as np\n\n\nimg_path = 'dandelion.jpg'\nimg = image.load_img(img_path, target_size=(28, 28))\nx = image.img_to_array(img)\nx.shape\n#img = x.astype('float32') / 255.0\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\npreds = model.predict(x)\nposition = np.argmax(preds)\nprint('Predicted:', le.inverse_transform([position]))"
        },
        {
            "cell_type": "code",
            "execution_count": 140,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "--2019-12-16 22:48:41--  https://images.all-free-download.com/images/graphiclarge/the_fragant_daisy_514090.jpg\nResolving images.all-free-download.com (images.all-free-download.com)... 207.182.153.238\nConnecting to images.all-free-download.com (images.all-free-download.com)|207.182.153.238|:443... connected.\nHTTP request sent, awaiting response... 200 OK\nLength: 75460 (74K) [image/jpeg]\nSaving to: 'the_fragant_daisy_514090.jpg'\n\n100%[======================================>] 75,460      --.-K/s   in 0.1s    \n\n2019-12-16 22:48:41 (653 KB/s) - 'the_fragant_daisy_514090.jpg' saved [75460/75460]\n\n"
                }
            ],
            "source": "!wget https://images.all-free-download.com/images/graphiclarge/the_fragant_daisy_514090.jpg"
        },
        {
            "cell_type": "code",
            "execution_count": 141,
            "metadata": {},
            "outputs": [],
            "source": "!mv the_fragant_daisy_514090.jpg daisy.jpg"
        },
        {
            "cell_type": "code",
            "execution_count": 142,
            "metadata": {},
            "outputs": [
                {
                    "name": "stdout",
                    "output_type": "stream",
                    "text": "Predicted: ['dandelion']\n"
                }
            ],
            "source": "from keras.preprocessing import image\nfrom keras.applications.resnet50 import preprocess_input, decode_predictions\nimport numpy as np\n\n\nimg_path = 'daisy.jpg'\nimg = image.load_img(img_path, target_size=(28, 28))\nx = image.img_to_array(img)\nx.shape\n#img = x.astype('float32') / 255.0\nx = np.expand_dims(x, axis=0)\nx = preprocess_input(x)\npreds = model.predict(x)\nposition = np.argmax(preds)\nprint('Predicted:', le.inverse_transform([position]))"
        },
        {
            "cell_type": "code",
            "execution_count": null,
            "metadata": {},
            "outputs": [],
            "source": ""
        }
    ],
    "metadata": {
        "kernelspec": {
            "display_name": "Python 3.6 with Spark",
            "language": "python3",
            "name": "python36"
        },
        "language_info": {
            "codemirror_mode": {
                "name": "ipython",
                "version": 3
            },
            "file_extension": ".py",
            "mimetype": "text/x-python",
            "name": "python",
            "nbconvert_exporter": "python",
            "pygments_lexer": "ipython3",
            "version": "3.6.8"
        }
    },
    "nbformat": 4,
    "nbformat_minor": 1
}